{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit-recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJBZSH4vq4u6",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSftB76LdPFH",
        "colab_type": "text"
      },
      "source": [
        "# Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iDiqNH522EbK",
        "colab": {}
      },
      "source": [
        "# Load the data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T8rvkzP621Zq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "948ce842-9041-4f40-e729-1d132608f9bd"
      },
      "source": [
        "# Show training data\n",
        "print(train.shape) # rows, columns\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 785)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8gOrtZyL26Tv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "5005d6db-d3de-4df9-eb49-14cc4d5fead7"
      },
      "source": [
        "# Show test data\n",
        "print(test.shape) # rows, columns\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0       0       0       0       0  ...         0         0         0         0\n",
              "1       0       0       0       0  ...         0         0         0         0\n",
              "2       0       0       0       0  ...         0         0         0         0\n",
              "3       0       0       0       0  ...         0         0         0         0\n",
              "4       0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n1zwfoKs3BEh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "681662ec-4de7-43a6-96ab-d356b24d7aa7"
      },
      "source": [
        "# Data visualization\n",
        "for i in range(6, 9):\n",
        "    plt.subplot(330 + (i+1))\n",
        "    plt.imshow(\n",
        "        train.iloc[i, 1:].values.reshape(28, 28), \n",
        "        cmap=plt.get_cmap('gray')\n",
        "    )\n",
        "    plt.title(train.iloc[i, 0]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQABMmMUdScG",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7f7NZeP8EVs",
        "colab": {}
      },
      "source": [
        "# Export input variables\n",
        "x_train = train.iloc[:40000, 1:].values.astype('float32') / 255.0\n",
        "x_validation = train.iloc[40000:, 1:].values.astype('float32') / 255.0\n",
        "x_test = test.values.astype('float32') / 255.0\n",
        "\n",
        "# Reshape input variables\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_validation = x_validation.reshape(x_validation.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Export labels\n",
        "y_train = train.iloc[:40000, 0].values.astype('int32')\n",
        "y_validation = train.iloc[40000:, 0].values.astype('int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Pf0calFekE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resize to 96 x 96 pixels\n",
        "x_train = tf.image.resize_with_crop_or_pad(x_train, 96, 96).numpy()\n",
        "x_validation = tf.image.resize_with_crop_or_pad(x_validation, 96, 96).numpy()\n",
        "x_test = tf.image.resize_with_crop_or_pad(x_test, 96, 96).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sODRqHq5Be_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define data augmentation step\n",
        "augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomTranslation(0.1, 0.1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HAHiGmm78eKK"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0id2Rlg8CWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model (taken from a tensorflow tutorial)\n",
        "model = keras.Sequential([\n",
        "    augmentation,\n",
        "    layers.InputLayer(input_shape=(96, 96, 1)),\n",
        "    layers.Conv2D(60, (3, 3), activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Conv2D(120, (2, 2), activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Conv2D(180, (2, 2), activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Conv2D(240, (2, 2), activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Conv2D(300, (2, 2), activation='relu'),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Conv2D(360, (2, 2), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NKBqhvdM8hry",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ_kJXKrdhgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a callback that saves the model\n",
        "callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath='model.h5',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F813CVI48i7W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee2e08e5-5027-42a2-93ea-309b4943960d"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x=x_train, \n",
        "    y=y_train, \n",
        "    epochs=200,\n",
        "    batch_size=100,\n",
        "    callbacks=[callback],\n",
        "    validation_data=(x_validation, y_validation)\n",
        ");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "  2/400 [..............................] - ETA: 24s - loss: 2.3138 - accuracy: 0.0850WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.1007s). Check your callbacks.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.2250 - accuracy: 0.1705WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_test_batch_end` time: 0.0317s). Check your callbacks.\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.86657, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 2.2250 - accuracy: 0.1705 - val_loss: 1.8666 - val_accuracy: 0.3255\n",
            "Epoch 2/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.6401 - accuracy: 0.3827\n",
            "Epoch 00002: val_loss improved from 1.86657 to 1.21317, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 1.6401 - accuracy: 0.3827 - val_loss: 1.2132 - val_accuracy: 0.5680\n",
            "Epoch 3/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.8404 - accuracy: 0.7043\n",
            "Epoch 00003: val_loss improved from 1.21317 to 0.44398, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.8404 - accuracy: 0.7043 - val_loss: 0.4440 - val_accuracy: 0.8680\n",
            "Epoch 4/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.8615\n",
            "Epoch 00004: val_loss improved from 0.44398 to 0.18660, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.4361 - accuracy: 0.8615 - val_loss: 0.1866 - val_accuracy: 0.9380\n",
            "Epoch 5/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.9094\n",
            "Epoch 00005: val_loss did not improve from 0.18660\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.3012 - accuracy: 0.9094 - val_loss: 0.2053 - val_accuracy: 0.9325\n",
            "Epoch 6/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9293\n",
            "Epoch 00006: val_loss improved from 0.18660 to 0.12995, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.2336 - accuracy: 0.9293 - val_loss: 0.1300 - val_accuracy: 0.9550\n",
            "Epoch 7/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9390\n",
            "Epoch 00007: val_loss improved from 0.12995 to 0.11713, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.2006 - accuracy: 0.9390 - val_loss: 0.1171 - val_accuracy: 0.9600\n",
            "Epoch 8/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9475\n",
            "Epoch 00008: val_loss improved from 0.11713 to 0.10710, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.1753 - accuracy: 0.9475 - val_loss: 0.1071 - val_accuracy: 0.9630\n",
            "Epoch 9/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9518\n",
            "Epoch 00009: val_loss improved from 0.10710 to 0.08242, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.1627 - accuracy: 0.9518 - val_loss: 0.0824 - val_accuracy: 0.9725\n",
            "Epoch 10/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9578\n",
            "Epoch 00010: val_loss improved from 0.08242 to 0.08229, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.1407 - accuracy: 0.9578 - val_loss: 0.0823 - val_accuracy: 0.9765\n",
            "Epoch 11/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9607\n",
            "Epoch 00011: val_loss improved from 0.08229 to 0.07488, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.1326 - accuracy: 0.9607 - val_loss: 0.0749 - val_accuracy: 0.9760\n",
            "Epoch 12/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.9604\n",
            "Epoch 00012: val_loss improved from 0.07488 to 0.06446, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.1307 - accuracy: 0.9604 - val_loss: 0.0645 - val_accuracy: 0.9785\n",
            "Epoch 13/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9635\n",
            "Epoch 00013: val_loss improved from 0.06446 to 0.06153, saving model to model.h5\n",
            "400/400 [==============================] - 45s 112ms/step - loss: 0.1211 - accuracy: 0.9635 - val_loss: 0.0615 - val_accuracy: 0.9795\n",
            "Epoch 14/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9674\n",
            "Epoch 00014: val_loss did not improve from 0.06153\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.1127 - accuracy: 0.9674 - val_loss: 0.0777 - val_accuracy: 0.9740\n",
            "Epoch 15/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9683\n",
            "Epoch 00015: val_loss improved from 0.06153 to 0.05142, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.1076 - accuracy: 0.9683 - val_loss: 0.0514 - val_accuracy: 0.9825\n",
            "Epoch 16/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9701\n",
            "Epoch 00016: val_loss improved from 0.05142 to 0.05124, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0992 - accuracy: 0.9701 - val_loss: 0.0512 - val_accuracy: 0.9850\n",
            "Epoch 17/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9713\n",
            "Epoch 00017: val_loss improved from 0.05124 to 0.05104, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0966 - accuracy: 0.9713 - val_loss: 0.0510 - val_accuracy: 0.9840\n",
            "Epoch 18/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9725\n",
            "Epoch 00018: val_loss did not improve from 0.05104\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0960 - accuracy: 0.9725 - val_loss: 0.0545 - val_accuracy: 0.9825\n",
            "Epoch 19/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9739\n",
            "Epoch 00019: val_loss improved from 0.05104 to 0.04574, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0890 - accuracy: 0.9739 - val_loss: 0.0457 - val_accuracy: 0.9860\n",
            "Epoch 20/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9743\n",
            "Epoch 00020: val_loss did not improve from 0.04574\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0863 - accuracy: 0.9743 - val_loss: 0.0462 - val_accuracy: 0.9875\n",
            "Epoch 21/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9753\n",
            "Epoch 00021: val_loss improved from 0.04574 to 0.04093, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0832 - accuracy: 0.9753 - val_loss: 0.0409 - val_accuracy: 0.9865\n",
            "Epoch 22/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9775\n",
            "Epoch 00022: val_loss improved from 0.04093 to 0.04058, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0782 - accuracy: 0.9775 - val_loss: 0.0406 - val_accuracy: 0.9880\n",
            "Epoch 23/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9769\n",
            "Epoch 00023: val_loss improved from 0.04058 to 0.03937, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0813 - accuracy: 0.9769 - val_loss: 0.0394 - val_accuracy: 0.9885\n",
            "Epoch 24/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9763\n",
            "Epoch 00024: val_loss did not improve from 0.03937\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0768 - accuracy: 0.9763 - val_loss: 0.0449 - val_accuracy: 0.9870\n",
            "Epoch 25/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9783\n",
            "Epoch 00025: val_loss did not improve from 0.03937\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0746 - accuracy: 0.9783 - val_loss: 0.0401 - val_accuracy: 0.9880\n",
            "Epoch 26/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9781\n",
            "Epoch 00026: val_loss improved from 0.03937 to 0.03831, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0726 - accuracy: 0.9781 - val_loss: 0.0383 - val_accuracy: 0.9885\n",
            "Epoch 27/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9780\n",
            "Epoch 00027: val_loss did not improve from 0.03831\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0729 - accuracy: 0.9780 - val_loss: 0.0385 - val_accuracy: 0.9885\n",
            "Epoch 28/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9794\n",
            "Epoch 00028: val_loss did not improve from 0.03831\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0689 - accuracy: 0.9794 - val_loss: 0.0425 - val_accuracy: 0.9880\n",
            "Epoch 29/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9790\n",
            "Epoch 00029: val_loss improved from 0.03831 to 0.03303, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0704 - accuracy: 0.9790 - val_loss: 0.0330 - val_accuracy: 0.9905\n",
            "Epoch 30/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9808\n",
            "Epoch 00030: val_loss did not improve from 0.03303\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0651 - accuracy: 0.9808 - val_loss: 0.0378 - val_accuracy: 0.9890\n",
            "Epoch 31/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9805\n",
            "Epoch 00031: val_loss did not improve from 0.03303\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0660 - accuracy: 0.9805 - val_loss: 0.0468 - val_accuracy: 0.9875\n",
            "Epoch 32/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9806\n",
            "Epoch 00032: val_loss improved from 0.03303 to 0.03128, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0652 - accuracy: 0.9806 - val_loss: 0.0313 - val_accuracy: 0.9895\n",
            "Epoch 33/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9812\n",
            "Epoch 00033: val_loss did not improve from 0.03128\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0621 - accuracy: 0.9812 - val_loss: 0.0364 - val_accuracy: 0.9890\n",
            "Epoch 34/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9808\n",
            "Epoch 00034: val_loss did not improve from 0.03128\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0635 - accuracy: 0.9808 - val_loss: 0.0333 - val_accuracy: 0.9910\n",
            "Epoch 35/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9827\n",
            "Epoch 00035: val_loss improved from 0.03128 to 0.03115, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0589 - accuracy: 0.9827 - val_loss: 0.0312 - val_accuracy: 0.9905\n",
            "Epoch 36/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9829\n",
            "Epoch 00036: val_loss improved from 0.03115 to 0.03005, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0588 - accuracy: 0.9829 - val_loss: 0.0301 - val_accuracy: 0.9900\n",
            "Epoch 37/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9823\n",
            "Epoch 00037: val_loss did not improve from 0.03005\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.0349 - val_accuracy: 0.9905\n",
            "Epoch 38/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9830\n",
            "Epoch 00038: val_loss did not improve from 0.03005\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0555 - accuracy: 0.9830 - val_loss: 0.0394 - val_accuracy: 0.9890\n",
            "Epoch 39/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9834\n",
            "Epoch 00039: val_loss did not improve from 0.03005\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0562 - accuracy: 0.9834 - val_loss: 0.0303 - val_accuracy: 0.9915\n",
            "Epoch 40/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9829\n",
            "Epoch 00040: val_loss improved from 0.03005 to 0.02941, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0577 - accuracy: 0.9829 - val_loss: 0.0294 - val_accuracy: 0.9900\n",
            "Epoch 41/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9829\n",
            "Epoch 00041: val_loss did not improve from 0.02941\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0576 - accuracy: 0.9829 - val_loss: 0.0300 - val_accuracy: 0.9895\n",
            "Epoch 42/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9834\n",
            "Epoch 00042: val_loss improved from 0.02941 to 0.02760, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0551 - accuracy: 0.9834 - val_loss: 0.0276 - val_accuracy: 0.9910\n",
            "Epoch 43/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9842\n",
            "Epoch 00043: val_loss did not improve from 0.02760\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0538 - accuracy: 0.9842 - val_loss: 0.0344 - val_accuracy: 0.9910\n",
            "Epoch 44/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9842\n",
            "Epoch 00044: val_loss did not improve from 0.02760\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.0311 - val_accuracy: 0.9905\n",
            "Epoch 45/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9843\n",
            "Epoch 00045: val_loss did not improve from 0.02760\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0525 - accuracy: 0.9843 - val_loss: 0.0307 - val_accuracy: 0.9905\n",
            "Epoch 46/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9849\n",
            "Epoch 00046: val_loss did not improve from 0.02760\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0495 - accuracy: 0.9849 - val_loss: 0.0297 - val_accuracy: 0.9915\n",
            "Epoch 47/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9844\n",
            "Epoch 00047: val_loss improved from 0.02760 to 0.02664, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.0266 - val_accuracy: 0.9920\n",
            "Epoch 48/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9851\n",
            "Epoch 00048: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.0268 - val_accuracy: 0.9925\n",
            "Epoch 49/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9851\n",
            "Epoch 00049: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0483 - accuracy: 0.9851 - val_loss: 0.0278 - val_accuracy: 0.9915\n",
            "Epoch 50/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9859\n",
            "Epoch 00050: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.0328 - val_accuracy: 0.9910\n",
            "Epoch 51/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9858\n",
            "Epoch 00051: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0503 - accuracy: 0.9858 - val_loss: 0.0274 - val_accuracy: 0.9925\n",
            "Epoch 52/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9850\n",
            "Epoch 00052: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.0293 - val_accuracy: 0.9915\n",
            "Epoch 53/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9858\n",
            "Epoch 00053: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0480 - accuracy: 0.9858 - val_loss: 0.0285 - val_accuracy: 0.9920\n",
            "Epoch 54/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9861\n",
            "Epoch 00054: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0471 - accuracy: 0.9861 - val_loss: 0.0267 - val_accuracy: 0.9920\n",
            "Epoch 55/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9851\n",
            "Epoch 00055: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.0281 - val_accuracy: 0.9915\n",
            "Epoch 56/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9869\n",
            "Epoch 00056: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0454 - accuracy: 0.9869 - val_loss: 0.0279 - val_accuracy: 0.9900\n",
            "Epoch 57/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9859\n",
            "Epoch 00057: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.0315 - val_accuracy: 0.9915\n",
            "Epoch 58/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9855\n",
            "Epoch 00058: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.0282 - val_accuracy: 0.9925\n",
            "Epoch 59/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9870\n",
            "Epoch 00059: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0461 - accuracy: 0.9870 - val_loss: 0.0307 - val_accuracy: 0.9915\n",
            "Epoch 60/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9872\n",
            "Epoch 00060: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.0309 - val_accuracy: 0.9900\n",
            "Epoch 61/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9864\n",
            "Epoch 00061: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0451 - accuracy: 0.9864 - val_loss: 0.0326 - val_accuracy: 0.9905\n",
            "Epoch 62/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9865\n",
            "Epoch 00062: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0462 - accuracy: 0.9865 - val_loss: 0.0271 - val_accuracy: 0.9910\n",
            "Epoch 63/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9874\n",
            "Epoch 00063: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0423 - accuracy: 0.9874 - val_loss: 0.0299 - val_accuracy: 0.9905\n",
            "Epoch 64/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9875\n",
            "Epoch 00064: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 0.0282 - val_accuracy: 0.9905\n",
            "Epoch 65/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9880\n",
            "Epoch 00065: val_loss did not improve from 0.02664\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 0.0295 - val_accuracy: 0.9910\n",
            "Epoch 66/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9874\n",
            "Epoch 00066: val_loss improved from 0.02664 to 0.02644, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
            "Epoch 67/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9879\n",
            "Epoch 00067: val_loss improved from 0.02644 to 0.02627, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.0263 - val_accuracy: 0.9910\n",
            "Epoch 68/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9879\n",
            "Epoch 00068: val_loss did not improve from 0.02627\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0411 - accuracy: 0.9879 - val_loss: 0.0339 - val_accuracy: 0.9905\n",
            "Epoch 69/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9879\n",
            "Epoch 00069: val_loss did not improve from 0.02627\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.0279 - val_accuracy: 0.9920\n",
            "Epoch 70/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9878\n",
            "Epoch 00070: val_loss did not improve from 0.02627\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.0302 - val_accuracy: 0.9920\n",
            "Epoch 71/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9880\n",
            "Epoch 00071: val_loss improved from 0.02627 to 0.02410, saving model to model.h5\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.0241 - val_accuracy: 0.9925\n",
            "Epoch 72/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9883\n",
            "Epoch 00072: val_loss did not improve from 0.02410\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 0.0296 - val_accuracy: 0.9905\n",
            "Epoch 73/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9893\n",
            "Epoch 00073: val_loss did not improve from 0.02410\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0382 - accuracy: 0.9893 - val_loss: 0.0323 - val_accuracy: 0.9910\n",
            "Epoch 74/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9881\n",
            "Epoch 00074: val_loss did not improve from 0.02410\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.0277 - val_accuracy: 0.9925\n",
            "Epoch 75/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9881\n",
            "Epoch 00075: val_loss did not improve from 0.02410\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0399 - accuracy: 0.9881 - val_loss: 0.0257 - val_accuracy: 0.9920\n",
            "Epoch 76/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9878\n",
            "Epoch 00076: val_loss did not improve from 0.02410\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.0294 - val_accuracy: 0.9920\n",
            "Epoch 77/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9879\n",
            "Epoch 00077: val_loss did not improve from 0.02410\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.0281 - val_accuracy: 0.9915\n",
            "Epoch 78/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9885\n",
            "Epoch 00078: val_loss improved from 0.02410 to 0.02396, saving model to model.h5\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 0.0240 - val_accuracy: 0.9930\n",
            "Epoch 79/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9884\n",
            "Epoch 00079: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0403 - accuracy: 0.9884 - val_loss: 0.0253 - val_accuracy: 0.9930\n",
            "Epoch 80/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9885\n",
            "Epoch 00080: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.0294 - val_accuracy: 0.9930\n",
            "Epoch 81/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9893\n",
            "Epoch 00081: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 0.0272 - val_accuracy: 0.9925\n",
            "Epoch 82/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9888\n",
            "Epoch 00082: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0389 - accuracy: 0.9888 - val_loss: 0.0248 - val_accuracy: 0.9940\n",
            "Epoch 83/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9893\n",
            "Epoch 00083: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0247 - val_accuracy: 0.9925\n",
            "Epoch 84/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9890\n",
            "Epoch 00084: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.0245 - val_accuracy: 0.9920\n",
            "Epoch 85/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9891\n",
            "Epoch 00085: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0356 - accuracy: 0.9891 - val_loss: 0.0243 - val_accuracy: 0.9920\n",
            "Epoch 86/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9889\n",
            "Epoch 00086: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.0267 - val_accuracy: 0.9925\n",
            "Epoch 87/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9887\n",
            "Epoch 00087: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.0264 - val_accuracy: 0.9935\n",
            "Epoch 88/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9885\n",
            "Epoch 00088: val_loss did not improve from 0.02396\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0294 - val_accuracy: 0.9905\n",
            "Epoch 89/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9888\n",
            "Epoch 00089: val_loss improved from 0.02396 to 0.02351, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0372 - accuracy: 0.9888 - val_loss: 0.0235 - val_accuracy: 0.9935\n",
            "Epoch 90/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9899\n",
            "Epoch 00090: val_loss did not improve from 0.02351\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 0.0278 - val_accuracy: 0.9925\n",
            "Epoch 91/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9891\n",
            "Epoch 00091: val_loss did not improve from 0.02351\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0245 - val_accuracy: 0.9935\n",
            "Epoch 92/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9895\n",
            "Epoch 00092: val_loss did not improve from 0.02351\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0350 - accuracy: 0.9895 - val_loss: 0.0294 - val_accuracy: 0.9920\n",
            "Epoch 93/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9893\n",
            "Epoch 00093: val_loss did not improve from 0.02351\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.0258 - val_accuracy: 0.9920\n",
            "Epoch 94/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9899\n",
            "Epoch 00094: val_loss did not improve from 0.02351\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0353 - accuracy: 0.9899 - val_loss: 0.0281 - val_accuracy: 0.9935\n",
            "Epoch 95/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9896\n",
            "Epoch 00095: val_loss did not improve from 0.02351\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0349 - accuracy: 0.9896 - val_loss: 0.0245 - val_accuracy: 0.9930\n",
            "Epoch 96/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9901\n",
            "Epoch 00096: val_loss did not improve from 0.02351\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0335 - accuracy: 0.9901 - val_loss: 0.0268 - val_accuracy: 0.9925\n",
            "Epoch 97/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9903\n",
            "Epoch 00097: val_loss improved from 0.02351 to 0.02200, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
            "Epoch 98/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9906\n",
            "Epoch 00098: val_loss did not improve from 0.02200\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0322 - accuracy: 0.9906 - val_loss: 0.0276 - val_accuracy: 0.9925\n",
            "Epoch 99/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9901\n",
            "Epoch 00099: val_loss did not improve from 0.02200\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
            "Epoch 100/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9892\n",
            "Epoch 00100: val_loss did not improve from 0.02200\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0229 - val_accuracy: 0.9940\n",
            "Epoch 101/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9898\n",
            "Epoch 00101: val_loss improved from 0.02200 to 0.02189, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0219 - val_accuracy: 0.9930\n",
            "Epoch 102/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9902\n",
            "Epoch 00102: val_loss did not improve from 0.02189\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0236 - val_accuracy: 0.9925\n",
            "Epoch 103/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9906\n",
            "Epoch 00103: val_loss did not improve from 0.02189\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0251 - val_accuracy: 0.9925\n",
            "Epoch 104/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9899\n",
            "Epoch 00104: val_loss did not improve from 0.02189\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 0.0271 - val_accuracy: 0.9935\n",
            "Epoch 105/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9901\n",
            "Epoch 00105: val_loss did not improve from 0.02189\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0339 - accuracy: 0.9901 - val_loss: 0.0234 - val_accuracy: 0.9935\n",
            "Epoch 106/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9906\n",
            "Epoch 00106: val_loss improved from 0.02189 to 0.02151, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 0.0215 - val_accuracy: 0.9935\n",
            "Epoch 107/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9904\n",
            "Epoch 00107: val_loss did not improve from 0.02151\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0328 - accuracy: 0.9904 - val_loss: 0.0237 - val_accuracy: 0.9935\n",
            "Epoch 108/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9899\n",
            "Epoch 00108: val_loss did not improve from 0.02151\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 0.0239 - val_accuracy: 0.9930\n",
            "Epoch 109/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9903\n",
            "Epoch 00109: val_loss did not improve from 0.02151\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.0236 - val_accuracy: 0.9940\n",
            "Epoch 110/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9905\n",
            "Epoch 00110: val_loss did not improve from 0.02151\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0253 - val_accuracy: 0.9925\n",
            "Epoch 111/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9906\n",
            "Epoch 00111: val_loss did not improve from 0.02151\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0229 - val_accuracy: 0.9930\n",
            "Epoch 112/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9905\n",
            "Epoch 00112: val_loss improved from 0.02151 to 0.01930, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0193 - val_accuracy: 0.9940\n",
            "Epoch 113/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9902\n",
            "Epoch 00113: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0251 - val_accuracy: 0.9940\n",
            "Epoch 114/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9907\n",
            "Epoch 00114: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0315 - accuracy: 0.9907 - val_loss: 0.0250 - val_accuracy: 0.9930\n",
            "Epoch 115/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9912\n",
            "Epoch 00115: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0236 - val_accuracy: 0.9935\n",
            "Epoch 116/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9910\n",
            "Epoch 00116: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.0244 - val_accuracy: 0.9940\n",
            "Epoch 117/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9907\n",
            "Epoch 00117: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0309 - accuracy: 0.9907 - val_loss: 0.0240 - val_accuracy: 0.9935\n",
            "Epoch 118/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9905\n",
            "Epoch 00118: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.0253 - val_accuracy: 0.9935\n",
            "Epoch 119/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9909\n",
            "Epoch 00119: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0239 - val_accuracy: 0.9940\n",
            "Epoch 120/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9908\n",
            "Epoch 00120: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.0223 - val_accuracy: 0.9935\n",
            "Epoch 121/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9909\n",
            "Epoch 00121: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.0264 - val_accuracy: 0.9940\n",
            "Epoch 122/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9904\n",
            "Epoch 00122: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.0241 - val_accuracy: 0.9930\n",
            "Epoch 123/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9910\n",
            "Epoch 00123: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0239 - val_accuracy: 0.9940\n",
            "Epoch 124/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9915\n",
            "Epoch 00124: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 0.0281 - val_accuracy: 0.9930\n",
            "Epoch 125/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9916\n",
            "Epoch 00125: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.0244 - val_accuracy: 0.9930\n",
            "Epoch 126/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9911\n",
            "Epoch 00126: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 0.0255 - val_accuracy: 0.9930\n",
            "Epoch 127/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9915\n",
            "Epoch 00127: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.0269 - val_accuracy: 0.9935\n",
            "Epoch 128/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9913\n",
            "Epoch 00128: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 0.0255 - val_accuracy: 0.9925\n",
            "Epoch 129/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9919\n",
            "Epoch 00129: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0232 - val_accuracy: 0.9940\n",
            "Epoch 130/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9912\n",
            "Epoch 00130: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0255 - val_accuracy: 0.9935\n",
            "Epoch 131/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9919\n",
            "Epoch 00131: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0230 - val_accuracy: 0.9945\n",
            "Epoch 132/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9912\n",
            "Epoch 00132: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.0237 - val_accuracy: 0.9945\n",
            "Epoch 133/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9912\n",
            "Epoch 00133: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0196 - val_accuracy: 0.9950\n",
            "Epoch 134/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9916\n",
            "Epoch 00134: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0273 - val_accuracy: 0.9925\n",
            "Epoch 135/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9908\n",
            "Epoch 00135: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.0217 - val_accuracy: 0.9930\n",
            "Epoch 136/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9912\n",
            "Epoch 00136: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0232 - val_accuracy: 0.9930\n",
            "Epoch 137/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9920\n",
            "Epoch 00137: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.0256 - val_accuracy: 0.9925\n",
            "Epoch 138/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9918\n",
            "Epoch 00138: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 0.0228 - val_accuracy: 0.9930\n",
            "Epoch 139/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9913\n",
            "Epoch 00139: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 0.0262 - val_accuracy: 0.9930\n",
            "Epoch 140/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9916\n",
            "Epoch 00140: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.0213 - val_accuracy: 0.9930\n",
            "Epoch 141/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9913\n",
            "Epoch 00141: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.0221 - val_accuracy: 0.9950\n",
            "Epoch 142/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9913\n",
            "Epoch 00142: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0224 - val_accuracy: 0.9940\n",
            "Epoch 143/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9923\n",
            "Epoch 00143: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0243 - val_accuracy: 0.9940\n",
            "Epoch 144/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9920\n",
            "Epoch 00144: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.0222 - val_accuracy: 0.9945\n",
            "Epoch 145/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9918\n",
            "Epoch 00145: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0260 - val_accuracy: 0.9930\n",
            "Epoch 146/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9923\n",
            "Epoch 00146: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
            "Epoch 147/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9919\n",
            "Epoch 00147: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 0.0231 - val_accuracy: 0.9940\n",
            "Epoch 148/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9923\n",
            "Epoch 00148: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.0234 - val_accuracy: 0.9935\n",
            "Epoch 149/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9927\n",
            "Epoch 00149: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.0227 - val_accuracy: 0.9940\n",
            "Epoch 150/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9926\n",
            "Epoch 00150: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0265 - val_accuracy: 0.9935\n",
            "Epoch 151/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9918\n",
            "Epoch 00151: val_loss did not improve from 0.01930\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0261 - val_accuracy: 0.9920\n",
            "Epoch 152/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9924\n",
            "Epoch 00152: val_loss improved from 0.01930 to 0.01850, saving model to model.h5\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.0185 - val_accuracy: 0.9935\n",
            "Epoch 153/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9919\n",
            "Epoch 00153: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0219 - val_accuracy: 0.9935\n",
            "Epoch 154/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9930\n",
            "Epoch 00154: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.0222 - val_accuracy: 0.9925\n",
            "Epoch 155/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9918\n",
            "Epoch 00155: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0246 - val_accuracy: 0.9945\n",
            "Epoch 156/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9921\n",
            "Epoch 00156: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0209 - val_accuracy: 0.9945\n",
            "Epoch 157/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9923\n",
            "Epoch 00157: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0227 - val_accuracy: 0.9925\n",
            "Epoch 158/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9926\n",
            "Epoch 00158: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0215 - val_accuracy: 0.9935\n",
            "Epoch 159/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9922\n",
            "Epoch 00159: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0219 - val_accuracy: 0.9930\n",
            "Epoch 160/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9926\n",
            "Epoch 00160: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0260 - val_accuracy: 0.9930\n",
            "Epoch 161/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9926\n",
            "Epoch 00161: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0266 - val_accuracy: 0.9925\n",
            "Epoch 162/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9927\n",
            "Epoch 00162: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.0238 - val_accuracy: 0.9915\n",
            "Epoch 163/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9923\n",
            "Epoch 00163: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0265 - val_accuracy: 0.9905\n",
            "Epoch 164/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9921\n",
            "Epoch 00164: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
            "Epoch 165/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9923\n",
            "Epoch 00165: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
            "Epoch 166/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9926\n",
            "Epoch 00166: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0240 - val_accuracy: 0.9925\n",
            "Epoch 167/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9922\n",
            "Epoch 00167: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0226 - val_accuracy: 0.9925\n",
            "Epoch 168/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9928\n",
            "Epoch 00168: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0211 - val_accuracy: 0.9945\n",
            "Epoch 169/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9928\n",
            "Epoch 00169: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0220 - val_accuracy: 0.9925\n",
            "Epoch 170/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9922\n",
            "Epoch 00170: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0230 - val_accuracy: 0.9935\n",
            "Epoch 171/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9929\n",
            "Epoch 00171: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.0251 - val_accuracy: 0.9920\n",
            "Epoch 172/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9928\n",
            "Epoch 00172: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0214 - val_accuracy: 0.9935\n",
            "Epoch 173/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9926\n",
            "Epoch 00173: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0220 - val_accuracy: 0.9930\n",
            "Epoch 174/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9931\n",
            "Epoch 00174: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0232 - val_accuracy: 0.9930\n",
            "Epoch 175/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9923\n",
            "Epoch 00175: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.0249 - val_accuracy: 0.9935\n",
            "Epoch 176/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9929\n",
            "Epoch 00176: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0239 - val_accuracy: 0.9925\n",
            "Epoch 177/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9926\n",
            "Epoch 00177: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
            "Epoch 178/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9926\n",
            "Epoch 00178: val_loss did not improve from 0.01850\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0231 - val_accuracy: 0.9915\n",
            "Epoch 179/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9929\n",
            "Epoch 00179: val_loss improved from 0.01850 to 0.01734, saving model to model.h5\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0173 - val_accuracy: 0.9950\n",
            "Epoch 180/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9931\n",
            "Epoch 00180: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0231 - val_accuracy: 0.9935\n",
            "Epoch 181/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9932\n",
            "Epoch 00181: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0243 - val_accuracy: 0.9925\n",
            "Epoch 182/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9935\n",
            "Epoch 00182: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.0219 - val_accuracy: 0.9930\n",
            "Epoch 183/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9927\n",
            "Epoch 00183: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0238 - val_accuracy: 0.9925\n",
            "Epoch 184/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9933\n",
            "Epoch 00184: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0209 - val_accuracy: 0.9930\n",
            "Epoch 185/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9924\n",
            "Epoch 00185: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.0200 - val_accuracy: 0.9935\n",
            "Epoch 186/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9932\n",
            "Epoch 00186: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0262 - val_accuracy: 0.9925\n",
            "Epoch 187/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9933\n",
            "Epoch 00187: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0222 - val_accuracy: 0.9935\n",
            "Epoch 188/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9936\n",
            "Epoch 00188: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0227 - val_accuracy: 0.9935\n",
            "Epoch 189/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9929\n",
            "Epoch 00189: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0221 - val_accuracy: 0.9940\n",
            "Epoch 190/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9935\n",
            "Epoch 00190: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.0267 - val_accuracy: 0.9920\n",
            "Epoch 191/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9926\n",
            "Epoch 00191: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0242 - val_accuracy: 0.9930\n",
            "Epoch 192/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9931\n",
            "Epoch 00192: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.0233 - val_accuracy: 0.9915\n",
            "Epoch 193/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9930\n",
            "Epoch 00193: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
            "Epoch 194/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9934\n",
            "Epoch 00194: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0198 - val_accuracy: 0.9940\n",
            "Epoch 195/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9934\n",
            "Epoch 00195: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0221 - val_accuracy: 0.9945\n",
            "Epoch 196/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9932\n",
            "Epoch 00196: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
            "Epoch 197/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9930\n",
            "Epoch 00197: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0238 - val_accuracy: 0.9940\n",
            "Epoch 198/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9935\n",
            "Epoch 00198: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0233 - val_accuracy: 0.9930\n",
            "Epoch 199/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9933\n",
            "Epoch 00199: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 111ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0227 - val_accuracy: 0.9930\n",
            "Epoch 200/200\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9938\n",
            "Epoch 00200: val_loss did not improve from 0.01734\n",
            "400/400 [==============================] - 44s 110ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0216 - val_accuracy: 0.9940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCBelonQdmFZ",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgdV7txh8krA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "69df48b0-f180-4994-f3f6-c686e8985b16"
      },
      "source": [
        "# Plot the learning curve\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.95, 1])\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDA1Eo2tFaiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b6bf57cb-7299-4970-8f4a-b4f47b1d8745"
      },
      "source": [
        "# Plot the learning curve\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 0.2])\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYFre0kUdptm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "99c0e4d3-6d70-44a2-cf6f-a9c26aa1a079"
      },
      "source": [
        "# Load the best model\n",
        "model = models.load_model('model.h5')\n",
        "model.evaluate(x=x_validation, y=y_validation);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1/63 [..............................] - ETA: 0s - loss: 1.8230e-04 - accuracy: 0.0400WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0056 - accuracy: 0.0313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TOb3ZAq49alb"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ih0vQ8OD9qcs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9aededcd-9588-4b3a-b09a-e3179e119b16"
      },
      "source": [
        "# Make prediction for test data\n",
        "predictions = np.argmax(model.predict(x_test), axis=-1)\n",
        "submission=pd.DataFrame({\n",
        "    \"ImageId\": list(range(1,len(predictions)+1)),\n",
        "    \"Label\": predictions\n",
        "    })\n",
        "submission.to_csv(\"submission.csv\", index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (100, 96, 96, 1) for input Tensor(\"sequential_input_1:0\", shape=(100, 96, 96, 1), dtype=float32), but it was called on an input with incompatible shape (32, 96, 96, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (100, 96, 96, 1) for input Tensor(\"random_translation_input:0\", shape=(100, 96, 96, 1), dtype=float32), but it was called on an input with incompatible shape (32, 96, 96, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}